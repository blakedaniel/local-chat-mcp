# =============================================================================
# Local Chat Agent - Environment Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# Main Application
# -----------------------------------------------------------------------------

# Server binding
APP_HOST=0.0.0.0
APP_PORT=8000

# Ollama API endpoint for the main refactoring LLM
OLLAMA_URL=http://localhost:11434/api/generate

# LLM model for code refactoring
MODEL_NAME=deepseek-coder-v2:16b

# Path to MCP server config (Claude format)
MCP_CONFIG_PATH=./mcp-servers.json

# Templates directory
TEMPLATES_DIR=./templates

# -----------------------------------------------------------------------------
# RAG MCP Server (packages/rag-mcp-server)
# -----------------------------------------------------------------------------

# Server binding
RAG_HOST=0.0.0.0
RAG_PORT=8001

# Ollama settings for RAG queries
RAG_OLLAMA_URL=http://localhost:11434
RAG_LLM_MODEL=gpt-oss:20b
RAG_EMBEDDING_MODEL=nomic-embed-text
RAG_REQUEST_TIMEOUT=240.0

# Qdrant vector database
RAG_QDRANT_HOST=localhost
RAG_QDRANT_PORT=6333
RAG_COLLECTION_NAME=rag_documents

# RAG chunking settings
RAG_CHUNK_SIZE=1024
RAG_CHUNK_OVERLAP=200
RAG_SIMILARITY_TOP_K=3

# Directory containing documents to index
RAG_DATA_DIR=./data

# -----------------------------------------------------------------------------
# GitHub MCP Server (optional, for npx-based GitHub integration)
# -----------------------------------------------------------------------------

# GITHUB_TOKEN=ghp_xxxxxxxxxxxx
